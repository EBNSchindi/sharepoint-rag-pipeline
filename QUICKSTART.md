# ğŸš€ SharePoint RAG Pipeline - Quick Start Guide

**Von 0 auf 100 in 3 Minuten!** ğŸš€ğŸ’¨

## âš¡ Der schnellste Weg (3 Befehle)

```bash
# 1. Projekt vorbereiten
cd sharepoint-rag-pipeline
cp .env.example .env

# 2. Setup ausfÃ¼hren
make setup

# 3. PDFs verarbeiten
make process INPUT=/path/to/your/pdfs
```

**Das war's!** ğŸ‰ Die Pipeline lÃ¤uft und verarbeitet Ihre Dokumente.

**âœ… Erfolgreich getestet:** Business Intelligence PDF (10 Seiten, 25.389 Zeichen â†’ 4 kontextuelle Chunks)

---

## ğŸ³ Docker Quick Start (Empfohlen)

### Voraussetzungen prÃ¼fen
```bash
# Docker verfÃ¼gbar?
docker --version          # Sollte 20.10+ sein
docker-compose --version  # Sollte 1.29+ sein

# Falls nicht installiert:
curl -fsSL https://get.docker.com | sh
```

### 1ï¸âƒ£ Basis-Setup (einmalig)
```bash
cd sharepoint-rag-pipeline

# Environment konfigurieren
cp .env.example .env
nano .env  # INPUT_DIR auf Ihr PDF-Verzeichnis setzen

# Container bauen
make setup
```

### 2ï¸âƒ£ Pipeline ausfÃ¼hren
```bash
# Option A: Mit Makefile (am einfachsten)
make process INPUT=/absolute/path/to/pdfs

# Option B: Mit docker-compose (nutzt .env)
docker-compose up rag-pipeline

# Option C: Mit docker run (explizite Pfade)
docker run --rm \
  -v "/absolute/path/to/pdfs:/app/input:ro" \
  -v "$(pwd)/data:/app/data" \
  sharepoint-rag-pipeline:latest
```

### 3ï¸âƒ£ Ergebnisse prÃ¼fen
```bash
# Verarbeitungsbericht ansehen
cat data/reports/latest_report.json | python -m json.tool

# Logs prÃ¼fen
make logs

# Web-Interface fÃ¼r Monitoring
make monitor  # http://localhost:8080
```

---

## ğŸ¯ Typische AnwendungsfÃ¤lle

### 1ï¸âƒ£ Einmalige Verarbeitung
```bash
# Test-Lauf (zeigt nur, was verarbeitet wÃ¼rde)
make process-dry INPUT=/path/to/pdfs

# Echte Verarbeitung
make process INPUT=/path/to/pdfs

# Mit mehr Kontrolle
docker run --rm \
  -v "/path/to/pdfs:/app/input:ro" \
  -v "$(pwd)/data:/app/data" \
  -e MAX_WORKERS=2 \
  -e MIN_QUALITY_SCORE=80 \
  sharepoint-rag-pipeline:latest
```

### 2ï¸âƒ£ Monatliche Automatisierung
```bash
# Scheduler einrichten
echo "CRON_SCHEDULE=0 2 1 * *" >> .env  # Jeden 1. des Monats um 2:00
make run-scheduled

# Status prÃ¼fen
make status
make logs-scheduler
```

### 3ï¸âƒ£ Development/Testing
```bash
# Entwicklungsumgebung starten
make setup-dev
make run-dev

# Tests ausfÃ¼hren
make test-all

# Jupyter Notebook fÃ¼r Analyse
make jupyter  # http://localhost:8888
```

### 4ï¸âƒ£ Monitoring & Debugging
```bash
make help              # Alle verfÃ¼gbaren Befehle
make logs             # Live-Logs anzeigen
make status           # Container-Status
make health           # Health-Check ausfÃ¼hren
make stats            # Resource-Usage
```

---

## âš™ï¸ Wichtige Einstellungen

### Environment Variables (.env)
```bash
# Wichtigste Einstellungen
INPUT_DIR=/path/to/sharepoint/pdfs    # Ihr PDF-Verzeichnis
MAX_WORKERS=4                         # Anzahl parallele Worker
MIN_QUALITY_SCORE=70                  # QualitÃ¤tsschwelle (0-100)
CRON_SCHEDULE=0 2 1 * *              # Monatlich um 2:00 Uhr

# Optional
OPENAI_API_KEY=your-api-key          # FÃ¼r erweiterte AI-Features
LOG_LEVEL=INFO                       # DEBUG fÃ¼r mehr Details
```

### Performance-Tuning
```bash
# FÃ¼r mehr Geschwindigkeit (mehr RAM benÃ¶tigt)
docker run -e MAX_WORKERS=8 sharepoint-rag-pipeline:latest

# FÃ¼r weniger RAM-Verbrauch
docker run -e MAX_WORKERS=2 --memory=2g sharepoint-rag-pipeline:latest

# Mit GPU-Beschleunigung (falls verfÃ¼gbar)
docker run --gpus all sharepoint-rag-pipeline:gpu
```

### Chunk-Einstellungen (config/pipeline.yaml)
```yaml
chunking:
  chunk_size: 1000        # Token pro Chunk
  chunk_overlap: 200      # Ãœberlappung zwischen Chunks
  strategy: "contextual"   # Intelligente Segmentierung

quality_validation:
  min_quality_score: 70   # QualitÃ¤tsschwelle
  check_completeness: true
```

---

## ğŸ”¥ HÃ¤ufige Probleme & 30-Sekunden-Fixes

### "Permission denied" bei Docker
```bash
# LÃ¶sung 1: Docker-Gruppe beitreten
sudo usermod -aG docker $USER
newgrp docker

# LÃ¶sung 2: Ownership korrigieren
sudo chown -R $USER:$USER ./data

# LÃ¶sung 3: Mit sudo
sudo make process INPUT=/path/to/pdfs
```

### "Out of memory" Fehler
```bash
# Memory-Limit erhÃ¶hen
docker run --memory=8g sharepoint-rag-pipeline:latest

# Weniger Worker
make process INPUT=/path MAX_WORKERS=2

# Swap aktivieren (Linux)
sudo fallocate -l 4G /swapfile && sudo mkswap /swapfile && sudo swapon /swapfile
```

### "File not found" bei Volumes
```bash
# âŒ Falsch (relative Pfade):
docker run -v "./pdfs:/app/input" ...

# âœ… Richtig (absolute Pfade):
docker run -v "/home/user/pdfs:/app/input" ...
docker run -v "$(pwd)/pdfs:/app/input" ...
make process INPUT=/absolute/path/to/pdfs
```

### Langsame Verarbeitung
```bash
# CPU-Auslastung prÃ¼fen
make stats

# Logs auf Fehler prÃ¼fen
make logs | grep ERROR

# Performance-Test
make test-performance
```

### ChromaDB Connection Error
```bash
# Kein Problem! Pipeline nutzt automatisch JSON-Fallback
# Oder explizit ChromaDB starten:
docker-compose --profile external-db up -d chromadb
```

---

## ğŸ”¬ Was passiert bei der Verarbeitung?

### Pipeline-Phasen
1. **ğŸ“„ Multi-Backend PDF-Extraktion**: PyMuPDF â†’ pdfplumber â†’ PyPDF2 (Fallback-Chain)
2. **ğŸ“ Intelligente Metadaten-Analyse**: Titel, Autoren, Datum, Dokumenttyp
3. **âœ‚ï¸ Contextual Chunking**: Hierarchie-bewusste Segmentierung
4. **ğŸ§  Context Enrichment**: 
   - Dokumenthierarchie (Kapitel â†’ Sektion â†’ Subsektionen)
   - Navigationskontext (Previous/Next/Related chunks)
   - Semantische Rollen (Main content, Prerequisites, etc.)
   - NLP-basierte Konzeptextraktion
5. **âœ… 7-stufige QualitÃ¤tsprÃ¼fung**: VollstÃ¤ndigkeit, KohÃ¤renz, Informationsdichte
6. **ğŸ’¾ Dual Storage**: ChromaDB (Vektoren) + SQLite (Metadaten) + JSON-Fallback

### Technische Features
- **Incremental Processing**: Hash-basierte Ã„nderungserkennung
- **Fault Tolerance**: Automatische Fallback-Modi bei Komponentenfehlern
- **Rich Metadata**: VollstÃ¤ndige Kontext-Information pro Chunk
- **Quality Scoring**: 0-100 Bewertung fÃ¼r jeden Chunk

**Ergebnis**: Production-ready Contextual RAG mit maximaler Robustheit! ğŸš€

---

## ğŸ“ˆ Beispiel-Output

### Console Output
```
ğŸš€ SharePoint RAG Pipeline v2.0.0
ğŸ“ Processing /data/sharepoint/pdfs
ğŸ“Š Found 42 PDF files (3 new, 39 unchanged)

[===================] 100% | 42/42 files | ETA: 00:00

âœ… PROCESSING COMPLETED
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total files: 42
Processed: 40 âœ… | Failed: 2 âŒ
Chunks created: 2,456 (avg: 61.4 per doc)
Quality score: 87.3 Â± 12.1 (min: 65, max: 98)
Processing time: 4m 12s (1.7 files/min)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### Report JSON (data/reports/latest_report.json)
```json
{
  "timestamp": "2024-01-15T14:30:00Z",
  "summary": {
    "total_files_processed": 42,
    "successful": 40,
    "failed": 2,
    "total_chunks_created": 2456,
    "average_quality_score": 87.3,
    "processing_time_seconds": 252.1
  },
  "performance": {
    "files_per_minute": 10.0,
    "chunks_per_second": 9.8,
    "memory_peak_mb": 2048,
    "storage_used_mb": 145.7
  },
  "quality_distribution": {
    "excellent": 23,  // 90-100
    "good": 15,       // 70-89
    "acceptable": 2,  // 50-69
    "poor": 0         // < 50
  }
}
```

---

## ğŸ“ Output erklÃ¤rt

```
data/
â”œâ”€â”€ vectors/              # ğŸ§  Vektor-Embeddings
â”‚   â”œâ”€â”€ chroma.sqlite3   # ChromaDB (primÃ¤r)
â”‚   â””â”€â”€ fallback/        # JSON-Fallback
â”œâ”€â”€ metadata/            # ğŸ“Š Metadaten
â”‚   â””â”€â”€ metadata.db      # SQLite mit allen Infos
â”œâ”€â”€ state/               # ğŸ”„ Processing State
â”‚   â””â”€â”€ file_hashes.json # FÃ¼r incremental updates
â”œâ”€â”€ reports/             # ğŸ“ˆ Berichte
â”‚   â”œâ”€â”€ latest_report.json
â”‚   â””â”€â”€ archive/         # Historische Reports
â””â”€â”€ logs/                # ğŸ“ Detaillierte Logs
    â””â”€â”€ contextual_pipeline.log
```

### Projektstruktur (VollstÃ¤ndig)
```
sharepoint-rag-pipeline/
â”œâ”€â”€ ğŸ³ Docker Files
â”‚   â”œâ”€â”€ Dockerfile              # Multi-stage Container
â”‚   â”œâ”€â”€ docker-compose.yml      # Services & Orchestrierung
â”‚   â”œâ”€â”€ .env.example           # Environment Template
â”‚   â””â”€â”€ Makefile               # 40+ vereinfachte Commands
â”œâ”€â”€ ğŸ—ï¸ Source Code
â”‚   â”œâ”€â”€ src/agents/            # AutoGen Agenten
â”‚   â”œâ”€â”€ src/pipeline/          # Pipeline-Orchestrierung
â”‚   â”œâ”€â”€ src/models/            # Datenmodelle
â”‚   â””â”€â”€ src/storage/           # Speicher-Backend
â”œâ”€â”€ âš™ï¸ Configuration
â”‚   â”œâ”€â”€ config/pipeline.yaml   # Hauptkonfiguration
â”‚   â””â”€â”€ config/context_rules.yaml # Kontext-Regeln
â”œâ”€â”€ ğŸš€ Main Scripts
â”‚   â”œâ”€â”€ run_pipeline.py        # Hauptskript
â”‚   â””â”€â”€ test_pipeline.py       # Test & Validierung
â””â”€â”€ ğŸ“š Documentation
    â”œâ”€â”€ QUICKSTART.md          # Diese Datei
    â”œâ”€â”€ DOCKER.md              # Container-Guide
    â””â”€â”€ INSTALLATION.md        # VollstÃ¤ndige Installation
```

---

## ğŸš€ Produktiv-Deployment

### Automatisierung einrichten
```bash
# Docker-Scheduler (empfohlen)
echo "CRON_SCHEDULE=0 2 1 * *" >> .env  # Monatlich
docker-compose --profile scheduled up -d rag-scheduler

# Oder systemweiter Cron-Job
sudo crontab -e
# Zeile hinzufÃ¼gen:
0 2 1 * * cd /opt/sharepoint-rag-pipeline && make process INPUT=/data/sharepoint/pdfs
```

### Monitoring & Alerting
```bash
# Web-Dashboard starten
make monitor  # http://localhost:8080

# Health-Check Endpoint
curl http://localhost:8000/health

# E-Mail Benachrichtigungen (Linux)
make process INPUT=/data/pdfs && \
  mail -s "âœ… RAG Pipeline Success" admin@company.com < data/reports/latest_report.json
```

### Cloud-Deployment
```bash
# Image fÃ¼r Registry bauen
docker build -t your-registry.com/rag-pipeline:v1.0 .
docker push your-registry.com/rag-pipeline:v1.0

# Kubernetes deployment
kubectl apply -f k8s-deployment.yaml

# Docker Swarm
docker stack deploy -c docker-compose.yml rag-stack
```

---

## âš¡ Performance & Optimierung

### ğŸš€ Geschwindigkeit optimieren
```bash
# Mehr Worker (CPU-intensive Aufgaben)
make process INPUT=/path/to/pdfs
docker run -e MAX_WORKERS=8 sharepoint-rag-pipeline:latest

# GPU-Beschleunigung (falls verfÃ¼gbar)
docker run --gpus all sharepoint-rag-pipeline:gpu
```

### ğŸ’¾ Speicher optimieren
```bash
# Weniger Worker bei begrenztem RAM
docker run -e MAX_WORKERS=2 --memory=2g sharepoint-rag-pipeline:latest

# Chunk-GrÃ¶ÃŸe reduzieren
docker run -e CHUNK_SIZE=500 -e CHUNK_OVERLAP=100 sharepoint-rag-pipeline:latest
```

### âš–ï¸ QualitÃ¤t vs. Geschwindigkeit
```bash
# Hohe QualitÃ¤t (langsamer)
docker run -e MIN_QUALITY_SCORE=90 sharepoint-rag-pipeline:latest

# Schnelle Verarbeitung (niedrigere Standards)
docker run -e MIN_QUALITY_SCORE=60 -e SKIP_OCR=true sharepoint-rag-pipeline:latest
```

### ğŸ“Š Benchmark-Zahlen
| Dokumente | Worker | Zeit | RAM |
|-----------|--------|------|-----|
| 10 PDFs | 4 | ~2 min | 1.5 GB |
| 100 PDFs | 4 | ~15 min | 2.5 GB |
| 100 PDFs | 8 | ~8 min | 4 GB |
| 1000 PDFs | 4 | ~2.5 h | 4 GB |

---

## ğŸ“ WeiterfÃ¼hrende Ressourcen

ğŸ“š **Dokumentation**
- [DOCKER.md](DOCKER.md) - VollstÃ¤ndiger Container-Guide
- [TROUBLESHOOTING.md](TROUBLESHOOTING.md) - ProblemlÃ¶sungen
- [ARCHITECTURE.md](ARCHITECTURE.md) - System-Design
- [API.md](API.md) - Entwickler-Referenz

ğŸ› ï¸ **Tools & Integration**
- [Makefile](Makefile) - Alle Befehle im Ãœberblick
- [docker-compose.yml](docker-compose.yml) - Service-Konfiguration
- [config/](config/) - Anpassbare Einstellungen

ğŸ’¬ **Support**
- GitHub Issues fÃ¼r Bug Reports
- Discussions fÃ¼r Fragen
- Wiki fÃ¼r Community-BeitrÃ¤ge

---

## ğŸ‰ Ready to Go!

**Herzlichen GlÃ¼ckwunsch!** Sie haben die SharePoint RAG Pipeline erfolgreich eingerichtet!

Die Pipeline verarbeitet nun Ihre Dokumente mit fortschrittlicher Kontext-Anreicherung und ist bereit fÃ¼r den produktiven Einsatz.

### ğŸš€ Immediate Next Steps
1. ğŸ“ PDFs in Ihr Verzeichnis legen
2. ğŸƒ `make process INPUT=/path/to/pdfs` ausfÃ¼hren
3. ğŸ“Š Ergebnisse in `data/reports/` prÃ¼fen
4. ğŸ” ChromaDB fÃ¼r RAG-Abfragen nutzen
5. ğŸ“ˆ Monitoring Dashboard aufrufen: `make monitor`

**Happy Processing!** ğŸš€ğŸ“„â¡ï¸ğŸ§ 