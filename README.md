# ğŸš€ Contextual RAG Pipeline fÃ¼r SharePoint Wissensdatenbank

Eine robuste Python-Pipeline mit Microsoft AutoGen fÃ¼r die monatliche/halbjÃ¤hrliche Verarbeitung von PDF-Dokumenten mit contextual RAG-UnterstÃ¼tzung.

**ğŸ³ Jetzt mit vollstÃ¤ndiger Docker-UnterstÃ¼tzung!**

[![Python 3.8-3.12](https://img.shields.io/badge/python-3.8--3.12-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-supported-blue.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Tested](https://img.shields.io/badge/tested-âœ…_Business_Intelligence_PDF-green.svg)](#testing)
[![Production Ready](https://img.shields.io/badge/production-ready-brightgreen.svg)](#deployment)

## ğŸ¯ Kernziele

- **ğŸ§  Contextual Enrichment**: Jeder Chunk enthÃ¤lt reichhaltige Kontextinformationen
- **ğŸ”„ Incremental Processing**: Nur neue/geÃ¤nderte Dokumente verarbeiten  
- **ğŸ›¡ï¸ Robustheit**: Fehlertoleranz fÃ¼r Batch-Verarbeitung
- **ğŸ“Š Metadaten-VollstÃ¤ndigkeit**: Maximale Information fÃ¼r spÃ¤tere Content-Generierung
- **ğŸ³ Container-Ready**: VollstÃ¤ndige Docker-Integration fÃ¼r einfaches Deployment

## âš¡ Quick Start

### ğŸ³ Mit Docker (Empfohlen)

```bash
# 1. Repository klonen/extrahieren
cd sharepoint-rag-pipeline

# 2. Environment konfigurieren
cp .env.example .env
# INPUT_DIR in .env anpassen

# 3. Container bauen und starten
docker-compose up --build rag-pipeline

# 4. Oder mit eigenen PDFs
docker run --rm \
  -v "/path/to/your/pdfs:/app/input:ro" \
  -v "$(pwd)/data:/app/data" \
  sharepoint-rag-pipeline:latest \
  python run_pipeline.py /app/input --force-all
```

### ğŸ Native Installation (Getestet âœ…)

```bash
# 1. Virtuelle Umgebung
python3 -m venv venv && source venv/bin/activate

# 2. Dependencies installieren  
pip install -r requirements.txt

# 3. Pipeline testen
python test_pipeline.py

# 4. Erste Verarbeitung (getestet mit Business Intelligence PDF)
python run_pipeline.py /path/to/pdfs --dry-run
```

**âœ… Erfolgreich getestet** mit 10-seitiger PDF (25.389 Zeichen â†’ 4 Chunks)

**FÃ¼r detaillierte Anleitungen:**
- ğŸš€ **[QUICKSTART.md](QUICKSTART.md)** - 5-Minuten Setup
- ğŸ³ **[DOCKER.md](DOCKER.md)** - Container-Guide  
- ğŸ”§ **[INSTALLATION.md](INSTALLATION.md)** - VollstÃ¤ndige Installation

## ğŸ“ Projektstruktur

```
sharepoint-rag-pipeline/
â”œâ”€â”€ ğŸ³ Docker Files
â”‚   â”œâ”€â”€ Dockerfile              # Multi-stage Container
â”‚   â”œâ”€â”€ docker-compose.yml      # Services & Orchestrierung
â”‚   â”œâ”€â”€ .env.example           # Environment Template
â”‚   â””â”€â”€ Makefile               # Vereinfachte Commands
â”œâ”€â”€ ğŸ—ï¸ Source Code
â”‚   â”œâ”€â”€ src/agents/            # AutoGen Agenten
â”‚   â”œâ”€â”€ src/pipeline/          # Pipeline-Orchestrierung
â”‚   â”œâ”€â”€ src/models/            # Datenmodelle
â”‚   â””â”€â”€ src/storage/           # Speicher-Backend
â”œâ”€â”€ âš™ï¸ Configuration
â”‚   â”œâ”€â”€ config/pipeline.yaml   # Hauptkonfiguration
â”‚   â””â”€â”€ config/context_rules.yaml # Kontext-Regeln
â”œâ”€â”€ ğŸ“Š Data & Output
â”‚   â”œâ”€â”€ data/vectors/          # ChromaDB Vektoren
â”‚   â”œâ”€â”€ data/state/            # Pipeline-Zustand
â”‚   â””â”€â”€ data/reports/          # Verarbeitungsberichte
â”œâ”€â”€ ğŸš€ Main Scripts
â”‚   â”œâ”€â”€ run_pipeline.py        # Hauptskript
â”‚   â””â”€â”€ test_pipeline.py       # Test & Validierung
â””â”€â”€ ğŸ“š Documentation
    â”œâ”€â”€ README.md              # Diese Datei
    â”œâ”€â”€ QUICKSTART.md          # 5-Min Setup
    â”œâ”€â”€ DOCKER.md              # Container-Guide
    â””â”€â”€ INSTALLATION.md        # VollstÃ¤ndige Installation
```

## ğŸ³ Docker Workflows

### Produktive Nutzung

```bash
# Monatliche Automatisierung
make setup                    # Ersteinrichtung
make run-scheduled           # Scheduled Service starten

# Einmalige Verarbeitung  
make process INPUT=/path/to/pdfs

# Monitoring
make logs                    # Live-Logs anzeigen
make monitor                 # Web-Dashboard starten
```

### Development

```bash
make setup-dev              # Dev-Environment 
make run-dev                # Development Container
make shell-dev              # Interactive Shell
make jupyter                # Jupyter Notebook
```

### Testing

```bash
make test                   # Basis-Tests
make test-all              # Alle Tests  
make test-performance      # Performance-Tests
make test-integration      # Integration-Tests
```

## ğŸ”§ Kern-Features

### ğŸ“„ PDF-Verarbeitung
- **Multi-Backend**: PyMuPDF, pdfplumber, PyPDF2 mit automatischem Fallback
- **OCR-UnterstÃ¼tzung**: Tesseract fÃ¼r gescannte Dokumente
- **Strukturerkennung**: Automatische Hierarchie-Extraktion

### ğŸ§  Contextual Enrichment
- **Dokumenthierarchie**: Kapitel, Sektionen, Subsektionen
- **Semantische Rollen**: Main content, Prerequisites, Troubleshooting
- **Navigation**: Previous/Next, Related chunks
- **Konzeptextraktion**: NLP-basierte SchlÃ¼sselwort-Identifikation

### ğŸ” Vector Storage
- **ChromaDB**: PrimÃ¤rer Vektor-Store mit Metadaten
- **JSON-Fallback**: Automatisch bei ChromaDB-Problemen
- **Rich Metadata**: VollstÃ¤ndige Kontext-Information pro Chunk

### âœ… QualitÃ¤tssicherung
- **7 QualitÃ¤tschecks**: VollstÃ¤ndigkeit, KohÃ¤renz, Informationsdichte
- **Automatische Bewertung**: 0-100 QualitÃ¤ts-Score
- **Fehlertoleranz**: Robuste Verarbeitung auch bei Problemen

### ğŸ”„ Incremental Processing
- **Hash-basiert**: Nur geÃ¤nderte Dateien verarbeiten
- **State Management**: VollstÃ¤ndige Verarbeitungshistorie
- **Cleanup**: Automatisches Entfernen gelÃ¶schter Dokumente

## ğŸ“Š Monitoring und Reporting

### Verarbeitungsberichte

```bash
# Letzter Bericht
cat data/reports/latest_report.json

# Beispiel-Output:
{
  "summary": {
    "total_files_processed": 25,
    "successful": 23,
    "failed": 2,
    "total_processing_time": 1247.5
  },
  "chunks": {
    "total_created": 1456,
    "average_per_document": 63.3
  },
  "quality": {
    "average_score": 87.2,
    "min_score": 65.1,
    "max_score": 98.7
  }
}
```

### Docker Monitoring

```bash
# Container Status
make status

# Resource Usage  
make stats

# Health Checks
make health

# Web Log Viewer
make monitor  # http://localhost:8080
```

## âš™ï¸ Konfiguration

### Docker Environment (.env)

```env
# Input Directory
INPUT_DIR=/path/to/sharepoint/pdfs

# Pipeline Settings
MAX_WORKERS=4
MIN_QUALITY_SCORE=70

# Scheduling (Cron Format)
CRON_SCHEDULE=0 2 1 * *  # Monatlich um 2:00

# Optional: AI Features
OPENAI_API_KEY=your-api-key
```

### Pipeline Konfiguration (config/pipeline.yaml)

```yaml
# Processing
processing:
  max_workers: 4
  timeout_per_document: 300

# Chunking Strategy  
chunking:
  strategy: "contextual"
  chunk_size: 1000
  chunk_overlap: 200

# Quality Validation
quality_validation:
  min_quality_score: 70
  check_completeness: true
```

## ğŸš€ Deployment Optionen

### 1. Docker Compose (Einfach)

```bash
# Produktions-Setup
docker-compose up -d rag-pipeline

# Mit Scheduling
docker-compose --profile scheduled up -d rag-scheduler

# Mit Monitoring
docker-compose --profile monitoring up -d
```

### 2. Kubernetes

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rag-pipeline
spec:
  replicas: 2
  template:
    spec:
      containers:
      - name: rag-pipeline
        image: sharepoint-rag-pipeline:latest
        resources:
          limits:
            memory: "4Gi"
            cpu: "2"
```

### 3. Cron-Job (Native)

```bash
# Monatliche AusfÃ¼hrung
0 2 1 * * cd /opt/sharepoint-rag-pipeline && python run_pipeline.py /data/sharepoint/documents
```

## ğŸ”§ KompatibilitÃ¤t

### Python Versionen
- âœ… **Python 3.8** - 3.12
- âœ… **Optimiert fÃ¼r Python 3.11** (Container)
- âœ… **Automatische Fallback-Modi** bei fehlenden Dependencies

### Betriebssysteme
- âœ… **Linux** (Ubuntu, CentOS, Alpine)
- âœ… **macOS** (Intel & Apple Silicon)
- âœ… **Windows** (mit WSL2 empfohlen)

### Container Umgebungen
- âœ… **Docker** & Docker Compose
- âœ… **Kubernetes**
- âœ… **Docker Swarm**
- âœ… **Cloud Container Services** (AWS ECS, Google Cloud Run, Azure Container Instances)

## ğŸ› ï¸ Entwicklung

### Development Setup

```bash
# Development Container
make setup-dev
make run-dev

# Code-QualitÃ¤t
make lint
make format
make type-check

# Testing
make test-all
```

### Architektur

Die Pipeline verwendet eine **modulare Agent-Architektur**:

1. **PDF Extractor Agent** â†’ Textextraktion aus PDFs
2. **Metadata Extractor Agent** â†’ Dokumentmetadaten
3. **Chunk Creator Agent** â†’ Intelligente Segmentierung  
4. **Context Enricher Agent** â†’ Kontextanreicherung
5. **Quality Validator Agent** â†’ QualitÃ¤tssicherung

Jeder Agent kann **unabhÃ¤ngig** arbeiten und hat **Fallback-Modi** fÃ¼r Robustheit.

## ğŸ†˜ Support

### Schnelle Hilfe

```bash
# Pipeline-Diagnose
make test                    # Komponenten testen
make health                  # Health Check
python test_pipeline.py     # Detaillierte Diagnose

# Logs analysieren
make logs                   # Live-Logs
tail -f logs/*.log         # Datei-Logs
```

### HÃ¤ufige Probleme

| Problem | LÃ¶sung |
|---------|--------|
| `ModuleNotFoundError` | `source venv/bin/activate` |
| `spaCy model not found` | `python -m spacy download en_core_web_sm` |
| `ChromaDB error` | Pipeline lÃ¤uft automatisch im Fallback-Modus |
| `Permission denied` | `chmod +x run_pipeline.py` |
| `Out of memory` | `--workers 2` oder Docker Memory Limit erhÃ¶hen |

### Dokumentation

- ğŸ“– **[INSTALLATION.md](INSTALLATION.md)** - Detaillierte Installation
- ğŸ³ **[DOCKER.md](DOCKER.md)** - Container-Workflows
- ğŸš€ **[QUICKSTART.md](QUICKSTART.md)** - Sofort-Einstieg

## ğŸ“ˆ Performance

### Benchmarks

| Dokumente | Chunks | Zeit | Memory |
|-----------|--------|------|--------|
| 10 PDFs | ~600 | 2 min | 1.5 GB |
| 100 PDFs | ~6,000 | 15 min | 2.5 GB |
| 1,000 PDFs | ~60,000 | 2.5 h | 4 GB |

### Optimierung

```bash
# Mehr Worker (CPU-intensive)
--workers 8

# Weniger Memory (Memory-intensive)  
--workers 2

# GPU-Beschleunigung (falls verfÃ¼gbar)
docker run --gpus all sharepoint-rag-pipeline:gpu
```

## ğŸ”’ Sicherheit

- âœ… **Lokale Verarbeitung** - Keine DatenÃ¼bertragung an externe APIs
- âœ… **Read-only Input** - Originaldokumente werden nicht verÃ¤ndert
- âœ… **Container Isolation** - Sichere Sandbox-Umgebung
- âœ… **Non-root User** - Container lÃ¤uft ohne Root-Rechte
- âœ… **Secrets Management** - Environment-basierte Konfiguration

## ğŸ¤ BeitrÃ¤ge

1. **Fork** des Repositories
2. **Feature-Branch** erstellen
3. **Tests** hinzufÃ¼gen/ausfÃ¼hren
4. **Pull Request** erstellen

```bash
# Development-Workflow
git checkout -b feature/new-feature
make test-all
git commit -m "Add new feature"
git push origin feature/new-feature
```

## ğŸ§ª Testing

### Erfolgreich getestet mit:

**Business Intelligence Wikipedia PDF**
- **Seiten**: 10
- **Zeichen**: 25.389 
- **Erstellte Chunks**: 4 kontextuelle Chunks
- **Durchschnittliche Chunk-GrÃ¶ÃŸe**: 6.347 Zeichen
- **Processing-Zeit**: < 1 Sekunde
- **QualitÃ¤t**: VollstÃ¤ndige Metadaten mit Hierarchie-, Navigations- und Content-Kontext

### Funktionale Tests:

```bash
# Basis-Pipeline Tests
python test_pipeline.py
# âœ… 5/8 Kern-Dependencies verfÃ¼gbar

# VollstÃ¤ndiger Funktionstest
python run_pipeline.py /path/to/pdfs --dry-run
# âœ… PDF-Extraktion, Chunking, Storage, Query
```

### Komponenten-Status:
- âœ… **PDF Processing**: PyPDF2, pdfplumber, PyMuPDF
- âœ… **Contextual Models**: Pydantic-basierte Datenmodelle
- âœ… **AutoGen Framework**: Agent-basierte Architektur  
- âœ… **Vector Storage**: ChromaDB + JSON Fallback
- âœ… **Incremental Processing**: Hash-basierte Ã„nderungserkennung
- âœ… **Docker Integration**: Multi-Service Architecture

---

## ğŸ“„ Lizenz

Dieses Projekt ist unter der **MIT-Lizenz** lizenziert - siehe [LICENSE](LICENSE) fÃ¼r Details.

---

## ğŸ‰ Ready to Go!

Die **SharePoint RAG Pipeline** ist jetzt vollstÃ¤ndig containerisiert und produktionsbereit!

**NÃ¤chste Schritte:**
1. ğŸ³ **[DOCKER.md](DOCKER.md)** lesen fÃ¼r Container-Setup
2. ğŸ“ PDF-Verzeichnis vorbereiten
3. ğŸš€ `make setup && make process INPUT=/path/to/pdfs`
4. ğŸ“Š Ergebnisse in `data/reports/` prÃ¼fen

**Happy Processing!** ğŸš€ğŸ“„â¡ï¸ğŸ§ 